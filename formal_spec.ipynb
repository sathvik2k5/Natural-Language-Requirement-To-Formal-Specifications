{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b577a13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import re\n",
    "from pyparsing import Word, alphas, Suppress, Group, Forward, OneOrMore, opAssoc, infixNotation\n",
    "from pyparsing import Keyword, CaselessKeyword, printables\n",
    "from pyparsing import restOfLine, quotedString\n",
    "from collections import deque\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "from sympy import Symbol\n",
    "from sympy.logic.boolalg import Equivalent\n",
    "\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('punkt_tab')\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1f44c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a function to check for logical equivalence (conceptual)\n",
    "def are_logically_equivalent(logic1: str, logic2: str, var_map: dict) -> bool:\n",
    "    \"\"\"\n",
    "    CONCEPTUAL FUNCTION:\n",
    "    Checks if two boolean logic strings are semantically equivalent.\n",
    "    This would be implemented using a formal logic library like pyeda or sympy.logic.\n",
    "    For now, it returns True only if the strings are identical, which is a weak check.\n",
    "    \"\"\"\n",
    "    # In a real implementation:\n",
    "    # 1. Parse logic1 and logic2 into ASTs.\n",
    "    # 2. Normalize variables using var_map.\n",
    "    # 3. Use pyeda.expr.expr('logic_string').equivalent(pyeda.expr.expr('other_logic_string'))\n",
    "    # For this conceptual implementation, we'll just do a strict string comparison.\n",
    "    return logic1.strip() == logic2.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99353ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_llm_for_boolean_logic(natural_language_requirement: str, bool_vars:list) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert in formal logic and system specifications.\n",
    "    Your task is to translate natural language design requirements into Boolean logic expressions.\n",
    "\n",
    "    Rules for Boolean Logic:\n",
    "    - Use 'AND' for logical conjunction.\n",
    "    - Use 'OR' for logical disjunction.\n",
    "    - Use 'NOT' for logical negation.\n",
    "    - Use 'IMPLIES' for logical implication (A IMPLIES B).\n",
    "    - Use parentheses for grouping everywhere so that its neatly understandable.\n",
    "    - Identify the clauses properly with more precision in the sentence and convert them into boolean specifications properly.\n",
    "    - Identify the main subject (e.g., 'software installation', 'system activation', 'alarm sounding') and include it as a variable in the final Boolean logic expression.\n",
    "    - Do not include any explanations, preamble, or additional text. Only output the Boolean logic expression.\n",
    "    - When you see 'only if' (not 'if') in the requirement like A only if B it is 'A implies B' not 'B implies A'\n",
    "    - When you see 'if and only if' (not 'only if') in the requirement like A if and only if B it is 'A implies B AND B implies A'\n",
    "\n",
    "    Use these boolean variables : \"{bool_vars}\"\n",
    "\n",
    "    Natural Language Requirement: \"{natural_language_requirement}\"\n",
    "\n",
    "    Boolean Logic:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model='llama3',\n",
    "            messages=[{'role': 'user', 'content': prompt}],\n",
    "            options={'temperature': 0.1, 'num_predict': 128}\n",
    "        )\n",
    "        llm_output = response['message']['content'].strip()\n",
    "        # print(f\"LLM Raw Output:\\n{llm_output}\\n\")\n",
    "        lines = [line.strip() for line in llm_output.split('\\n') if line.strip()]\n",
    "        if lines:\n",
    "            return lines[0]\n",
    "        else:\n",
    "            return \"Error: LLM returned empty response.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error communicating with Ollama: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f58a4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_completeness(original_requirement: str, full_logic: str):\n",
    "    \"\"\"\n",
    "    Measures LLM completeness by removing sentences and checking if the logic changes.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Measuring Completeness via Sentence Deletion ---\")\n",
    "    \n",
    "    # 1. Split the original requirement into sentences\n",
    "    sentences = sent_tokenize(original_requirement)\n",
    "    if len(sentences) <= 1:\n",
    "        print(\"  Skipping completeness check: Requirement is a single sentence.\")\n",
    "        return 0, 0 # Returns (sentences_incorporated, total_sentences)\n",
    "    \n",
    "    sentences_incorporated = 0\n",
    "    total_sentences = len(sentences)\n",
    "    \n",
    "    for i, sentence_to_remove in enumerate(sentences):\n",
    "        # 2. Create a modified requirement by removing one sentence\n",
    "        modified_sentences = [s for j, s in enumerate(sentences) if i != j]\n",
    "        modified_requirement = \" \".join(modified_sentences)\n",
    "        \n",
    "        print(f\"\\n  --- Deleting Sentence #{i+1} ---\")\n",
    "        print(f\"  Sentence Removed: '{sentence_to_remove}'\")\n",
    "        print(f\"  Modified Requirement: '{modified_requirement}'\")\n",
    "        \n",
    "        # 3. Get the LLM's new logic for the modified requirement\n",
    "        try:\n",
    "            modified_logic = ask_llm_for_boolean_logic(modified_requirement)\n",
    "        except Exception as e:\n",
    "            print(f\"  Error getting modified logic from LLM: {e}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"  Modified Logic: '{modified_logic}'\")\n",
    "        print(f\"  Full Logic:     '{full_logic}'\")\n",
    "\n",
    "        # 4. Check for logical equivalence (Conceptual)\n",
    "        # This part requires a real equivalence checker. For now, we'll just do a strict string match.\n",
    "        is_equivalent = are_logically_equivalent(full_logic, modified_logic, {})\n",
    "        \n",
    "        if not is_equivalent:\n",
    "            print(\"  -> LOGIC CHANGED. Sentence was successfully incorporated.\")\n",
    "            sentences_incorporated += 1\n",
    "        else:\n",
    "            print(\"  -> LOGIC DID NOT CHANGE. Sentence was NOT incorporated (possible incompleteness).\")\n",
    "            # Note: This could also mean the sentence was redundant.\n",
    "            \n",
    "    completeness_score = sentences_incorporated / total_sentences if total_sentences > 0 else 0\n",
    "    print(f\"\\nCompleteness Score: {sentences_incorporated}/{total_sentences} ({completeness_score:.2f})\")\n",
    "    return sentences_incorporated, total_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec287ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Pyparsing Grammar and Helper Functions ---\n",
    "def parse_boolean_logic(expression_string: str):\n",
    "    AND = CaselessKeyword(\"AND\")\n",
    "    OR = CaselessKeyword(\"OR\")\n",
    "    NOT = CaselessKeyword(\"NOT\")\n",
    "    IMPLIES = CaselessKeyword(\"IMPLIES\")\n",
    "    variable_name = Word(alphas, alphas + \"_\")\n",
    "    operand = Group(variable_name | Suppress(\"(\") + Forward().setResultsName(\"nested_expr\") + Suppress(\")\"))\n",
    "    boolean_expression = Forward()\n",
    "    boolean_expression <<= infixNotation(\n",
    "    operand,\n",
    "    [\n",
    "        (NOT, 1, opAssoc.RIGHT),  # Highest precedence\n",
    "        (AND, 2, opAssoc.LEFT),\n",
    "        (OR, 2, opAssoc.LEFT),\n",
    "        (IMPLIES, 2, opAssoc.RIGHT),  # Lowest precedence\n",
    "    ]\n",
    "    )\n",
    "    try:\n",
    "        parsed_expression = boolean_expression.parseString(expression_string, parseAll=True)\n",
    "        return parsed_expression[0]\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing expression: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dbd632b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_operator_and_operands(node):\n",
    "    if not isinstance(node, list):\n",
    "        return None, node\n",
    "    if len(node) == 2 and isinstance(node[0], str) and node[0].upper() == 'NOT':\n",
    "        return node[0].upper(), [node[1]]\n",
    "    if len(node) > 3 and all(isinstance(node[i], str) and node[i].upper() == node[1].upper() for i in range(1, len(node), 2)):\n",
    "        current_op = node[1].upper()\n",
    "        last_op_index = -1\n",
    "        for i in range(len(node) - 1, 0, -1):\n",
    "            if isinstance(node[i], str) and node[i].upper() == current_op:\n",
    "                last_op_index = i\n",
    "                break\n",
    "        if last_op_index != -1:\n",
    "            left_subtree_node = node[0:last_op_index]\n",
    "            right_operand_node = node[last_op_index+1]\n",
    "            return current_op, [left_subtree_node, right_operand_node]\n",
    "    elif len(node) == 3 and isinstance(node[1], str) and node[1].upper() in ['AND', 'OR', 'IMPLIES']:\n",
    "        return node[1].upper(), [node[0], node[2]]\n",
    "    elif len(node) == 1:\n",
    "        return _get_operator_and_operands(node[0])\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b866e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_tree(node, level=0, prefix=\"Node: \"):\n",
    "    indent = \"  \" * level\n",
    "    op, operands = _get_operator_and_operands(node)\n",
    "    if op:\n",
    "        print(f\"{indent}{prefix}{op}\")\n",
    "        if op == 'NOT':\n",
    "            visualize_tree(operands[0], level + 1, \"Operand: \")\n",
    "        elif op in ['AND', 'OR', 'IMPLIES']:\n",
    "            visualize_tree(operands[0], level + 1, \"Left: \")\n",
    "            visualize_tree(operands[1], level + 1, \"Right: \")\n",
    "    elif operands is not None:\n",
    "        print(f\"{indent}{prefix}{operands}\")\n",
    "    else:\n",
    "        print(f\"{indent}{prefix}UNEXPECTED NODE (Please report): {node} (Type: {type(node).__name__})\")\n",
    "        if isinstance(node, list):\n",
    "            for item in node:\n",
    "                visualize_tree(item, level + 1, \"Item: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "95ef7c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_tree(node, indent=0):\n",
    "    prefix = \"  \" * indent\n",
    "    op, operands = _get_operator_and_operands(node)\n",
    "    if op:\n",
    "        print(f\"{prefix}{op}\")\n",
    "        for operand in operands:\n",
    "            pretty_print_tree(operand, indent + 1)\n",
    "    elif operands is not None:\n",
    "        print(f\"{prefix}{operands}\")\n",
    "    else:\n",
    "        print(f\"{prefix}UNEXPECTED NODE (Please report): {node} (Type: {type(node).__name__})\")\n",
    "        if isinstance(node, list):\n",
    "            for item in node:\n",
    "                pretty_print_tree(item, indent + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a6c3122f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_variables(node, variables: set):\n",
    "    op, operands = _get_operator_and_operands(node)\n",
    "    if op:\n",
    "        for operand in operands:\n",
    "            extract_variables(operand, variables)\n",
    "    elif operands is not None:\n",
    "        variables.add(operands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7911dbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- New Function for Semantic Equivalence Mapping ---\n",
    "def get_semantic_equivalents(variable_name: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Asks the LLM for a list of semantically equivalent terms for a given variable.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Given the following concept expressed as a capitalized variable name, provide a comma-separated list of \n",
    "    semantically equivalent or synonymous terms. The terms should also be in capitalized, underscore-separated format.\n",
    "    Do not include any explanations, preamble, or the original term itself.\n",
    "    \n",
    "    Example:\n",
    "    'TEMPERATURE_HIGH' -> 'HIGH_TEMPERATURE,TEMP_EXCEEDS_THRESHOLD'\n",
    "    'USER_AUTHENTICATED' -> 'AUTHENTICATED_USER,USER_LOGGED_IN'\n",
    "    \n",
    "    Input Variable: '{variable_name}'\n",
    "    \n",
    "    Equivalent Terms:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model='llama3',\n",
    "            messages=[{'role': 'user', 'content': prompt}],\n",
    "            options={'temperature': 0.1, 'num_predict': 128}\n",
    "        )\n",
    "        llm_output = response['message']['content'].strip()\n",
    "        terms = [term.strip() for term in llm_output.split(',') if term.strip()]\n",
    "        return terms\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting semantic equivalents for '{variable_name}': {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "642d7ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Your original evaluation metrics (commented out for now) ---\n",
    "def evaluate_metrics(llm_outputs: list[str], ground_truths: list[str]):\n",
    "    \"\"\"\n",
    "    Evaluates a batch of LLM outputs against their corresponding ground truths.\n",
    "    Calculates overall accuracy and false positive rate.\n",
    "    \"\"\"\n",
    "    assert len(llm_outputs) == len(ground_truths), \"Mismatched list lengths\"\n",
    "    R = W = 0\n",
    "    GT = RS = len(ground_truths)\n",
    "    for llm_output, ground_truth in zip(llm_outputs, ground_truths):\n",
    "        llm_clean = llm_output.strip().replace(\" \", \"\")\n",
    "        gt_clean = ground_truth.strip().replace(\" \", \"\")\n",
    "        if llm_clean == gt_clean:\n",
    "            R += 1\n",
    "        else:\n",
    "            W += 1\n",
    "    accuracy = R / GT if GT > 0 else 0\n",
    "    false_positive = W / RS if RS > 0 else 0\n",
    "    return accuracy, false_positive, R, W, GT, RS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "304f7e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bleu_score(llm_output: str, ground_truth: str) -> float:\n",
    "    reference = [ground_truth.split()]\n",
    "    candidate = llm_output.split()\n",
    "    return sentence_bleu(reference, candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2902f6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function sends a prompt to the LLM to perform deconstruction.\n",
    "def ask_llm_for_deconstruction(natural_language_requirement: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert in formal logic and system specifications.\n",
    "    Your task is to break down a complex natural language requirement into a list of simple, atomic sentences.\n",
    "    Each sentence should represent a single, clear logical proposition.\n",
    "    Ensure that the output is concise and free of repetitive or redundant sentences; if similar sentences occur, only include one version.\n",
    "\n",
    "    Rules for Output:\n",
    "    - Return a comma-separated list of the unique simple sentences.\n",
    "    - Do not include any explanations, preamble, or additional text.\n",
    "    - Do not use any boolean logic keywords (AND, OR, NOT, IMPLIES).\n",
    "    \n",
    "    Example:\n",
    "    Input: \"If a fire is detected, an alert must activate, and the system should only be active during business hours.\"\n",
    "    Output: \"a fire is detected, an alert must activate, the system should only be active during business hours\"\n",
    "\n",
    "    Natural Language Requirement: \"{natural_language_requirement}\"\n",
    "\n",
    "    Simple Sentences:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model='llama3',\n",
    "            messages=[{'role': 'user', 'content': prompt}],\n",
    "            options={'temperature': 0.1, 'num_predict': 256}\n",
    "        )\n",
    "        llm_output = response['message']['content'].strip()\n",
    "        return llm_output\n",
    "    except Exception as e:\n",
    "        return f\"Error communicating with Ollama: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9bc17905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the new `deconstruct_requirement` function.\n",
    "def deconstruct_requirement(natural_language: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Asks an LLM to deconstruct a single, complex requirement into a list of simple sentences.\n",
    "    \"\"\"\n",
    "    print(\"DEBUG: Asking LLM to deconstruct the requirement.\")\n",
    "    llm_output_string = ask_llm_for_deconstruction(natural_language)\n",
    "    \n",
    "    # Parse the comma-separated list from the LLM output.\n",
    "    simple_sentences = [s.strip() for s in llm_output_string.split(',') if s.strip()]\n",
    "    \n",
    "    return simple_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c583219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_logically_equivalent_conceptual(logic1: str, logic2: str) -> bool:\n",
    "    \"\"\"\n",
    "    CONCEPTUAL IMPLEMENTATION: Checks if two boolean logic strings are semantically equivalent\n",
    "    using a formal logic library. This code is for demonstration and will not run\n",
    "    without the 'sympy' library installed.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        normalized_logic1 = logic1\n",
    "        normalized_logic2 = logic2\n",
    "        \n",
    "        parsed_expr1 = parse_boolean_expression_to_sympy(normalized_logic1)\n",
    "        parsed_expr2 = parse_boolean_expression_to_sympy(normalized_logic2)\n",
    "        \n",
    "        return bool(Equivalent(parsed_expr1, parsed_expr2))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during logical equivalence check: {e}\")\n",
    "        return False\n",
    "    \n",
    "def parse_boolean_expression_to_sympy(expression: str):\n",
    "\n",
    "    expression = expression.replace('AND', '&').replace('OR', '|').replace('NOT', '~').replace('IMPLIES', '>>')\n",
    "    variables = re.findall(r'\\b[A-Z_]+\\b', expression)\n",
    "    symbols = {var: Symbol(var) for var in variables}\n",
    "\n",
    "    return expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a756f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_logic(c: str, s_list: list[str], d: str, pos: int, n: int, logic_main: str) -> None:\n",
    "    if(pos==n-1):\n",
    "        prompt_and_s = f\"{d} Additionally, {s_list[pos]}.\"\n",
    "        print(f\"\\n  Testing Another Case: \")\n",
    "        print(f\"  Input Prompt: '{prompt_and_s}'\")\n",
    "        \n",
    "        logic_and_s = ask_llm_for_boolean_logic(prompt_and_s)\n",
    "        print(f\"  LLM Output: {logic_and_s}\")\n",
    "        s_boolean = ask_llm_for_boolean_logic(s_list[pos])\n",
    "        curr_logic = f\"{logic_main} AND ({s_boolean})\"\n",
    "\n",
    "        are_they = are_logically_equivalent_conceptual(logic_and_s, curr_logic)\n",
    "        if(are_they):\n",
    "            print(\"Consistent!!!!!!\")\n",
    "        else:\n",
    "            print(\"Not Consistent!!!!!\")\n",
    "\n",
    "        print(\"\\n------------------------------------\")\n",
    "\n",
    "        prompt_and_not_s = f\"{d} However, it is not the case that {s_list[pos]}.\"\n",
    "        print(f\"\\n  Testing Another Case: \")\n",
    "        print(f\"  Input Prompt: '{prompt_and_not_s}'\")\n",
    "        logic_and_not_s = ask_llm_for_boolean_logic(prompt_and_not_s)\n",
    "        print(f\"  LLM Output: {logic_and_not_s}\")\n",
    "        not_logic = f\"It is not the case that {s_list[pos]}\"\n",
    "        s_boolean = ask_llm_for_boolean_logic(not_logic)\n",
    "        curr_logic = f\"{logic_main} AND ({s_boolean})\"\n",
    "\n",
    "        are_they = are_logically_equivalent_conceptual(logic_and_not_s, curr_logic)\n",
    "        if(are_they):\n",
    "            print(\"Consistent!!!!!!\")\n",
    "        else:\n",
    "            print(\"Not Consistent!!!!!\")\n",
    "\n",
    "        print(\"\\n------------------------------------\")\n",
    "\n",
    "        prompt = f\"{d}\"\n",
    "        print(f\"\\n  Testing Another Case: \")\n",
    "        print(f\"  Input Prompt: '{prompt}'\")\n",
    "        logic = ask_llm_for_boolean_logic(prompt)\n",
    "        print(f\"  LLM Output: {logic}\")\n",
    "\n",
    "        are_they = are_logically_equivalent_conceptual(logic, logic_main)\n",
    "        if(are_they):\n",
    "            print(\"Consistent!!!!!!\")\n",
    "        else:\n",
    "            print(\"Not Consistent!!!!!\")\n",
    "\n",
    "        print(\"\\n------------------------------------\")\n",
    "    else:\n",
    "        prompt_and_s = f\"{d} Additionally, {s_list[pos]}.\"\n",
    "        s_boolean = ask_llm_for_boolean_logic(s_list[pos])\n",
    "        curr_logic = f\"{logic_main} AND ({s_boolean})\"\n",
    "        check_logic(c,s_list,prompt_and_s,pos+1,n,curr_logic)\n",
    "\n",
    "        prompt_and_not_s = f\"{d} However, it is not the case that {s_list[pos]}.\"\n",
    "        not_logic = f\"It is not the case that {s_list[pos]}\"\n",
    "        s_boolean = ask_llm_for_boolean_logic(not_logic)\n",
    "        curr_logic = f\"{logic_main} AND ({s_boolean})\"\n",
    "        check_logic(c,s_list,prompt_and_not_s,pos+1,n,curr_logic)\n",
    "        \n",
    "        prompt = f\"{d}\"\n",
    "        check_logic(c,s_list,prompt,pos+1,n,logic_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6fb0096d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_compositional_logic(c: str, s_list: list[str], logic: str) -> None:\n",
    "    \"\"\"\n",
    "    Evaluates the LLM's ability to handle compositional logic (c AND s) and (c AND (NOT s)).\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Evaluating Compositional Logic ---\")\n",
    "    \n",
    "    n = len(s_list)\n",
    "    check_logic(c,s_list,c,0,n,logic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6d5b2484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_llm_direct(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Sends the exact prompt string to the LLM without any additional formatting.\n",
    "    Returns the raw LLM response.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model='llama3',\n",
    "            messages=[{'role': 'user', 'content': prompt}],\n",
    "            options={'temperature': 0.1, 'num_predict': 128}\n",
    "        )\n",
    "        return response['message']['content'].strip()\n",
    "    except Exception as e:\n",
    "        return f\"Error communicating with Ollama: {e}\"\n",
    "\n",
    "def manual_prompt_testing(natural_language_requirement: str = None, llm_boolean_logic_output: str = None):\n",
    "    \"\"\"\n",
    "    Allows you to manually test different prompts and count attempts.\n",
    "    \"\"\"\n",
    "    attempts = 0\n",
    "    results = []\n",
    "    \n",
    "    print(\"Manual Prompt Testing Mode - Type your prompts directly\")\n",
    "    print(\"Type 'quit' to exit\\n\")\n",
    "    \n",
    "    while True:\n",
    "        user_prompt = input(\"Enter your prompt: \").strip()\n",
    "        \n",
    "        if user_prompt.lower() == 'quit':\n",
    "            break\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "                    You are an expert in formal logic and system specifications.\n",
    "                    Your task is to translate natural language design requirements into Boolean logic expressions.\n",
    "\n",
    "    Rules for Boolean Logic:\n",
    "    - Use 'AND' for logical conjunction.\n",
    "    - Use 'OR' for logical disjunction.\n",
    "    - Use 'NOT' for logical negation.\n",
    "    - Use 'IMPLIES' for logical implication (A IMPLIES B).\n",
    "    - Use parentheses for grouping everywhere so that its neatly understandable.\n",
    "    - Identify the clauses properly with more precision in the sentence and convert them into boolean specifications properly.\n",
    "    - Variables should be capitalized single words (e.g., 'DOOR_OPEN', 'ALARM_ACTIVE').\n",
    "    - Identify the main subject (e.g., 'software installation', 'system activation', 'alarm sounding') and include it as a variable in the final Boolean logic expression.\n",
    "    - Do not include any explanations, preamble, or additional text. Only output the Boolean logic expression.\n",
    "    - When you see 'only if' (not 'if') in the requirement like A only if B it is 'A implies B' not 'B implies A'\n",
    "    - When you see 'if and only if' (not 'only if') in the requirement like A if and only if B it is 'A implies B AND B implies A'\n",
    "\n",
    "                    Natural Language Requirement: \"{natural_language_requirement}\"\n",
    "\n",
    "                    LLM Boolean Logic Output: \"{llm_boolean_logic_output}\"\n",
    "                    The issue: {user_prompt}\n",
    "                    \n",
    "                    Generate the appropriate boolean logic expression for the above problem.\n",
    "                    Give only the boolean logic expression as output.\n",
    "                    \"\"\"\n",
    "            \n",
    "        attempts += 1\n",
    "        llm_response = ask_llm_direct(prompt)\n",
    "        \n",
    "        print(f\"\\nAttempt {attempts}:\")\n",
    "        print(f\"Your prompt: '{prompt}'\")\n",
    "        print(f\"LLM response: {llm_response}\\n\")\n",
    "        \n",
    "        results.append({\n",
    "            'attempt': attempts,\n",
    "            'prompt': user_prompt,\n",
    "            'response': llm_response\n",
    "        })\n",
    "        llm_boolean_logic_output = llm_response\n",
    "    \n",
    "    print(f\"\\nTesting completed. Total attempts: {attempts}\")\n",
    "    return results, attempts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b76732f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_llm_for_boolean_variables(simple_sentences: list):\n",
    "    \"\"\"\n",
    "    Breaks a requirement into simple sentences and asks the LLM to\n",
    "    convert each sentence into a single Boolean variable name.\n",
    "    \"\"\"\n",
    "    \n",
    "    variable_map = {}\n",
    "\n",
    "    for sentence in enumerate(simple_sentences, start=1):\n",
    "        prompt = f\"\"\"\n",
    "        You are an expert in formal logic and system specifications.\n",
    "        Convert the following simple requirement sentence into a Boolean variable name.\n",
    "\n",
    "        Rules:\n",
    "        - Use CAPITALIZED words with underscores (e.g., DOOR_OPEN, SYSTEM_ACTIVE).\n",
    "        - The variable should directly represent the condition or event described in the sentence.\n",
    "        - Do NOT write Boolean operators (AND, OR, NOT, IMPLIES).\n",
    "        - If the sentence expresses a negative condition (e.g., contains \"not\", \"no\", etc.), generate the variable name representing the positive form. For example, \"Notifications will not appear\" should become \"NOTIFICATIONS_APPEARS\".\n",
    "        - Output only the variable name, nothing else.\n",
    "\n",
    "        Sentence: \"{sentence}\"\n",
    "\n",
    "        Boolean Variable:\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = ollama.chat(\n",
    "                model=\"llama3\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                options={\"temperature\": 0.1, \"num_predict\": 32}\n",
    "            )\n",
    "            var_name = response[\"message\"][\"content\"].strip().split()[0]\n",
    "            variable_map[sentence] = var_name\n",
    "        except Exception as e:\n",
    "            variable_map[sentence] = f\"Error: {e}\"\n",
    "\n",
    "    return variable_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cc3dc98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_semantic_consistency(requirement: str, boolean_logic: str, bool_vars: list) -> str:\n",
    "    \"\"\"\n",
    "    Asks the LLM to check if the Boolean logic is semantically consistent \n",
    "    with the natural language requirement.\n",
    "    Returns 'consistent', 'inconsistent', or a descriptive correction.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Requirement: \"{requirement}\"\n",
    "    Boolean Logic: \"{boolean_logic}\"\n",
    "    Allowed Boolean Variables: {bool_vars}\n",
    "\n",
    "    Task:\n",
    "    - Check if the Boolean logic correctly represents the requirement.\n",
    "    - If consistent, reply exactly: CONSISTENT\n",
    "    - If inconsistent, reply with the corrected boolean logic. Give only the boolean logic expression as output.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model=\"llama3\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            options={\"temperature\": 0.2, \"num_predict\": 256}\n",
    "        )\n",
    "        return response[\"message\"][\"content\"].strip()\n",
    "    except Exception as e:\n",
    "        return f\"Error checking consistency: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c5da7a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robust comparator that works with SymPy exprs, pyparsing ParseResults, and nested lists/tuples.\n",
    "from sympy import sympify, Symbol\n",
    "import re\n",
    "try:\n",
    "    from pyparsing import ParseResults\n",
    "except Exception:\n",
    "    class ParseResults:  # fallback dummy if pyparsing not available at import time\n",
    "        pass\n",
    "\n",
    "VAR_TOKEN_RE = re.compile(r\"\\b[A-Z][A-Z0-9_]*\\b\")  # heuristic for variables like SERVICE_STARTS_AUTOMATICALLY\n",
    "\n",
    "def is_sympy_expr(obj):\n",
    "    # ensure 'atoms' is callable (to avoid objects with an 'atoms' attribute that's not the method)\n",
    "    return hasattr(obj, 'atoms') and callable(getattr(obj, 'atoms')) and hasattr(obj, 'args')\n",
    "\n",
    "def is_parse_results(obj):\n",
    "    return isinstance(obj, ParseResults)\n",
    "\n",
    "def normalize_expr_if_str(expr_input):\n",
    "    \"\"\"If expr_input is a string using NOT/AND/OR/IF tokens, try to sympify, otherwise return original.\"\"\"\n",
    "    if expr_input is None:\n",
    "        return None\n",
    "    if isinstance(expr_input, str):\n",
    "        s = expr_input.upper()\n",
    "        s = re.sub(r\"\\bNOT\\b\", \"~\", s)\n",
    "        s = re.sub(r\"\\bAND\\b\", \"&\", s)\n",
    "        s = re.sub(r\"\\bOR\\b\", \"|\", s)\n",
    "        s = re.sub(r\"\\bIF\\b\", \">>\", s)\n",
    "        try:\n",
    "            return sympify(s, evaluate=False)\n",
    "        except Exception:\n",
    "            try:\n",
    "                return sympify(s)\n",
    "            except Exception:\n",
    "                # not a sympy parseable string, keep original string (we'll parse tree-style later)\n",
    "                return expr_input\n",
    "    return expr_input\n",
    "\n",
    "def walk_obj_nodes(node):\n",
    "    \"\"\"\n",
    "    Generic walker: yields (node_obj, parent_obj) for all sub-nodes in the parsed structure.\n",
    "    Supports:\n",
    "      - SymPy expressions: yields the sympy nodes\n",
    "      - pyparsing.ParseResults: yields each ParseResults and its children\n",
    "      - lists / tuples / dicts: yields each element\n",
    "      - strings / atoms: yields themselves as leaves\n",
    "    \"\"\"\n",
    "    seen = set()\n",
    "    def rec(n, parent=None):\n",
    "        nid = id(n)\n",
    "        if nid in seen:\n",
    "            return\n",
    "        seen.add(nid)\n",
    "        yield n, parent\n",
    "        # SymPy: iterate .args\n",
    "        if is_sympy_expr(n):\n",
    "            for a in getattr(n, 'args', ()):\n",
    "                yield from rec(a, n)\n",
    "        # ParseResults: iterate like list/dict\n",
    "        elif is_parse_results(n):\n",
    "            for a in list(n):\n",
    "                yield from rec(a, n)\n",
    "            # ParseResults can have named results too\n",
    "            try:\n",
    "                for k in n.keys():\n",
    "                    try:\n",
    "                        v = n.get(k)\n",
    "                        yield from rec(v, n)\n",
    "                    except Exception:\n",
    "                        pass\n",
    "            except Exception:\n",
    "                pass\n",
    "        # list/tuple/set\n",
    "        elif isinstance(n, (list, tuple, set)):\n",
    "            for a in n:\n",
    "                yield from rec(a, n)\n",
    "        # dict\n",
    "        elif isinstance(n, dict):\n",
    "            for k, v in n.items():\n",
    "                yield from rec(k, n)\n",
    "                yield from rec(v, n)\n",
    "        # strings or leaves: no further descend\n",
    "        else:\n",
    "            return\n",
    "    yield from rec(node)\n",
    "\n",
    "def atoms_from_node(node):\n",
    "    \"\"\"\n",
    "    Return a sorted list of candidate atom names (variable names) found in the node.\n",
    "    - For SymPy expressions use .atoms(Symbol) safely (guard against unexpected attributes)\n",
    "    - For other nodes, heuristically extract tokens matching VAR_TOKEN_RE from str(node)\n",
    "    \"\"\"\n",
    "    if node is None:\n",
    "        return []\n",
    "    # Safe SymPy path\n",
    "    if is_sympy_expr(node):\n",
    "        try:\n",
    "            sym_atoms = node.atoms(Symbol)\n",
    "            return sorted({str(a) for a in sym_atoms if isinstance(a, Symbol)})\n",
    "        except Exception:\n",
    "            # fallback to textual heuristics\n",
    "            pass\n",
    "    # If ParseResults or other object, try string heuristics\n",
    "    s = str(node)\n",
    "    found = VAR_TOKEN_RE.findall(s)\n",
    "    # filter out operator-like tokens if any (e.g., AND/OR/NOT might be uppercase; remove them)\n",
    "    found = [f for f in found if f not in (\"AND\",\"OR\",\"NOT\",\"IF\",\"IMPLIES\",\"TRUE\",\"FALSE\")]\n",
    "    return sorted(set(found))\n",
    "\n",
    "def node_type_name(node):\n",
    "    \"\"\"Readable type name for reporting.\"\"\"\n",
    "    try:\n",
    "        return type(node).__name__\n",
    "    except Exception:\n",
    "        return str(type(node))\n",
    "\n",
    "def detect_nl_exception_structure(nl_text):\n",
    "    # be defensive: accept non-string nl_text by casting to str\n",
    "    if nl_text is None:\n",
    "        s = \"\"\n",
    "    else:\n",
    "        s = str(nl_text).lower()\n",
    "    flags = {\"has_unless_like\": False, \"exception_connective\": None, \"implication_like\": False}\n",
    "    if re.search(r\"\\b(unless|but not if|except if|except when|but not when)\\b\", s):\n",
    "        flags[\"has_unless_like\"] = True\n",
    "    if re.search(r\"\\bif\\b\", s):\n",
    "        flags[\"implication_like\"] = True\n",
    "    m = re.search(r\"(but not if|unless|except if|except when)(.*)\", s)\n",
    "    if m:\n",
    "        part = m.group(2)\n",
    "        if ' or ' in part:\n",
    "            flags[\"exception_connective\"] = 'or'\n",
    "        elif ' and ' in part:\n",
    "            flags[\"exception_connective\"] = 'and'\n",
    "    else:\n",
    "        if re.search(r\"\\bnot\\b.*\\bor\\b\", s) or re.search(r\"\\bor\\b.*\\bnot\\b\", s):\n",
    "            flags[\"exception_connective\"] = 'or'\n",
    "        elif ' and ' in s and 'not' in s:\n",
    "            flags[\"exception_connective\"] = 'and'\n",
    "    return flags\n",
    "\n",
    "def compare_subtrees_to_nl_general(parsed_tree, nl_requirement, semantic_map=None):\n",
    "    \"\"\"\n",
    "    General comparator that accepts:\n",
    "      - SymPy expressions (or strings that sympify)\n",
    "      - pyparsing.ParseResults\n",
    "      - nested lists/tuples/dicts\n",
    "    semantic_map: optional dict mapping variable name -> NL fragment\n",
    "    Returns: list of issue dicts. Each issue includes:\n",
    "      - 'node' : repr(node)  (string repr for human reading)\n",
    "      - 'node_type': actual type name\n",
    "      - 'vars': vars found in that node (list)\n",
    "      - 'issue_type', 'message'\n",
    "    \"\"\"\n",
    "    # Normalize only if it's a string that looks like SymPy-friendly boolean expression\n",
    "    parsed = normalize_expr_if_str(parsed_tree)\n",
    "\n",
    "    nl_flags = detect_nl_exception_structure(nl_requirement)\n",
    "    issues = []\n",
    "\n",
    "    # Build set of mapped variables that are actually mentioned in NL (verbatim)\n",
    "    nl_mentions = set()\n",
    "    if semantic_map:\n",
    "        for v, frag in semantic_map.items():\n",
    "            if frag and frag.lower() in str(nl_requirement).lower():\n",
    "                nl_mentions.add(v)\n",
    "\n",
    "    # Walk the nodes\n",
    "    for node, parent in walk_obj_nodes(parsed):\n",
    "        node_repr = repr(node)\n",
    "        node_str = str(node)\n",
    "        node_tname = node_type_name(node)\n",
    "        vars_here = atoms_from_node(node)\n",
    "\n",
    "        # Heuristic: unexpected negation (detect if node is a negation node in SymPy or if its string begins with 'Not(' or '~' or 'NOT ')\n",
    "        is_negation_node = False\n",
    "        if is_sympy_expr(node) and hasattr(node, 'func') and getattr(node, 'func').__name__.lower() == \"not\":\n",
    "            is_negation_node = True\n",
    "        else:\n",
    "            # textual heuristics for parse trees: start with NOT/NOT( or prefix '~'\n",
    "            if isinstance(node, str):\n",
    "                if re.match(r'^\\s*(NOT\\b|~|NOT\\()', node_str, flags=re.IGNORECASE):\n",
    "                    is_negation_node = True\n",
    "            else:\n",
    "                # look at repr for common Not indicators\n",
    "                if re.search(r'\\bNot\\b|\\bNOT\\b|~', node_repr):\n",
    "                    # but be conservative: ensure it contains a single variable or small expression\n",
    "                    is_negation_node = True\n",
    "\n",
    "        if is_negation_node and len(vars_here) == 1:\n",
    "            atom = vars_here[0]\n",
    "            frag = semantic_map.get(atom, \"\") if semantic_map else \"\"\n",
    "            # If mapping exists and NL doesn't contain a negation for that fragment -> warn\n",
    "            if frag and ('not' not in frag.lower()) and (frag.lower() not in str(nl_requirement).lower()):\n",
    "                issues.append({\n",
    "                    \"node\": node_repr,\n",
    "                    \"node_type\": node_tname,\n",
    "                    \"vars\": vars_here,\n",
    "                    \"issue_type\": \"unexpected_negation\",\n",
    "                    \"message\": f\"Node appears to be a negation of {atom}, but NL fragment mapped to {atom!r} is not negative in requirement.\"\n",
    "                })\n",
    "\n",
    "        # Heuristic: connective mismatch for exception phrases\n",
    "        # Identify connective type of this node if possible: 'And' or 'Or'\n",
    "        node_connective = None\n",
    "        if is_sympy_expr(node) and hasattr(node, 'func'):\n",
    "            node_connective = getattr(node, 'func').__name__ if hasattr(node, 'func') else None\n",
    "        else:\n",
    "            # textual heuristics\n",
    "            if re.search(r'\\bAND\\b', node_str, flags=re.IGNORECASE) or re.search(r'&', node_str):\n",
    "                node_connective = \"And\"\n",
    "            elif re.search(r'\\bOR\\b', node_str, flags=re.IGNORECASE) or re.search(r'\\|', node_str):\n",
    "                node_connective = \"Or\"\n",
    "\n",
    "        if nl_flags[\"has_unless_like\"] and len(vars_here) >= 2 and node_connective in (\"And\", \"Or\"):\n",
    "            if nl_flags[\"exception_connective\"] == 'or' and node_connective == \"And\":\n",
    "                issues.append({\n",
    "                    \"node\": node_repr,\n",
    "                    \"node_type\": node_tname,\n",
    "                    \"vars\": vars_here,\n",
    "                    \"issue_type\": \"connective_mismatch\",\n",
    "                    \"message\": f\"NL suggests 'or' between exceptions, but node uses AND: {node_str}\"\n",
    "                })\n",
    "            if nl_flags[\"exception_connective\"] == 'and' and node_connective == \"Or\":\n",
    "                issues.append({\n",
    "                    \"node\": node_repr,\n",
    "                    \"node_type\": node_tname,\n",
    "                    \"vars\": vars_here,\n",
    "                    \"issue_type\": \"connective_mismatch\",\n",
    "                    \"message\": f\"NL suggests 'and' between exceptions, but node uses OR: {node_str}\"\n",
    "                })\n",
    "\n",
    "        # Heuristic: implication translated as disjunction\n",
    "        # If NL implication-like and top-level object is an OR that contains negation of primary atom\n",
    "        # We'll only perform this check on the root node (i.e., parent is None)\n",
    "        if nl_flags[\"implication_like\"] and parent is None:\n",
    "            # consider current node as root\n",
    "            root_str = str(parsed)\n",
    "            # detect OR at top level heuristically\n",
    "            root_is_or = False\n",
    "            if is_sympy_expr(parsed) and getattr(parsed, 'func', None) is not None and getattr(parsed, 'func').__name__ == \"Or\":\n",
    "                root_is_or = True\n",
    "            else:\n",
    "                if re.search(r'\\bOR\\b', root_str) or '|' in root_str:\n",
    "                    root_is_or = True\n",
    "            if root_is_or:\n",
    "                # find primary candidates from semantic_map\n",
    "                primary_candidates = []\n",
    "                if semantic_map:\n",
    "                    for v, frag in semantic_map.items():\n",
    "                        if frag and re.search(r\"\\b(start|enable|allow|open|activate|authenticate|login|startup)\\b\", frag.lower()):\n",
    "                            primary_candidates.append(v)\n",
    "                if not primary_candidates:\n",
    "                    primary_candidates = [v for v,f in (semantic_map or {}).items() if f and f.lower() in str(nl_requirement).lower()]\n",
    "                if not primary_candidates:\n",
    "                    primary_candidates = atoms_from_node(parsed)\n",
    "                for cand in primary_candidates:\n",
    "                    if re.search(r'(~|Not\\()' + re.escape(cand), root_str) or f\"~{cand}\" in root_str or f\"Not({cand})\" in root_str:\n",
    "                        issues.append({\n",
    "                            \"node\": repr(parsed),\n",
    "                            \"node_type\": node_type_name(parsed),\n",
    "                            \"vars\": atoms_from_node(parsed),\n",
    "                            \"issue_type\": \"implication_translated_as_disjunction\",\n",
    "                            \"message\": f\"NL suggests an implication/exception, but root expression is an OR containing negation of primary atom ({cand}): {root_str}\"\n",
    "                        })\n",
    "                        break\n",
    "\n",
    "        # Heuristic: unmapped variable checks (var appears but its mapped NL fragment not present verbatim in requirement)\n",
    "        if semantic_map:\n",
    "            for v in vars_here:\n",
    "                if semantic_map.get(v) and semantic_map[v].lower() not in str(nl_requirement).lower():\n",
    "                    issues.append({\n",
    "                        \"node\": node_repr,\n",
    "                        \"node_type\": node_tname,\n",
    "                        \"vars\": vars_here,\n",
    "                        \"issue_type\": \"unmapped_variable\",\n",
    "                        \"message\": f\"Variable {v} appears in node but its mapped NL fragment is not found verbatim in requirement. Mapped fragment: {semantic_map[v]!r}\"\n",
    "                    })\n",
    "\n",
    "    # de-duplicate issues by (node, issue_type, message) for clarity\n",
    "    unique = []\n",
    "    seen = set()\n",
    "    for it in issues:\n",
    "        key = (it.get('node'), it.get('issue_type'), it.get('message'))\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        unique.append(it)\n",
    "    return unique\n",
    "\n",
    "# Convenience wrapper that prints human-readable info (like run_comparator)\n",
    "def run_comparator_general(parsed_tree, nl_requirement, semantic_map=None, pretty_print=True):\n",
    "    issues = compare_subtrees_to_nl_general(parsed_tree, nl_requirement, semantic_map)\n",
    "    if pretty_print:\n",
    "        if not issues:\n",
    "            print(\"No issues detected.\")\n",
    "            return issues\n",
    "        print(\"Issues detected:\")\n",
    "        for i, it in enumerate(issues, 1):\n",
    "            # print node type and a short repr to inspect actual parsed node object\n",
    "            node_short = (it['node'][:400] + '...') if len(it['node']) > 400 else it['node']\n",
    "            print(f\"{i}. [{it['issue_type']}] {it['message']}\")\n",
    "            print(f\"    node_type: {it['node_type']}  node_repr: {node_short}\")\n",
    "            print(f\"    vars: {it.get('vars')}\\n\")\n",
    "    return issues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cd7f6a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_llm_for_boolean_logic_revised(natural_language_requirement: str, bool_vars:list, issues, llm_boolean_logic_output) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert in formal logic and system specifications.\n",
    "    Your task is to translate natural language design requirements into Boolean logic expressions.\n",
    "\n",
    "    Rules for Boolean Logic:\n",
    "    - Use 'AND' for logical conjunction.\n",
    "    - Use 'OR' for logical disjunction.\n",
    "    - Use 'NOT' for logical negation.\n",
    "    - Use 'IMPLIES' for logical implication (A IMPLIES B).\n",
    "    - Use parentheses for grouping everywhere so that its neatly understandable.\n",
    "    - Identify the clauses properly with more precision in the sentence and convert them into boolean specifications properly.\n",
    "    - Identify the main subject (e.g., 'software installation', 'system activation', 'alarm sounding') and include it as a variable in the final Boolean logic expression.\n",
    "    - Do not include any explanations, preamble, or additional text. Only output the Boolean logic expression.\n",
    "    - When you see 'only if' (not 'if') in the requirement like A only if B it is 'A implies B' not 'B implies A'\n",
    "    - When you see 'if and only if' (not 'only if') in the requirement like A if and only if B it is 'A implies B AND B implies A'\n",
    "\n",
    "    Use these boolean variables : \"{bool_vars}\"\n",
    "\n",
    "    For this Natural Language Requirement: \"{natural_language_requirement}\", the boolean logic output LLM gave was \n",
    "    Boolean Logic: \"{llm_boolean_logic_output}\"\n",
    "\n",
    "    But there are some issues here and they are,\n",
    "    Issues: \"{issues}\"\n",
    "\n",
    "    Fix the boolean logic and give me just the new corrected boolean logic.\n",
    "\n",
    "    Corrected Boolean Logic:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model='llama3',\n",
    "            messages=[{'role': 'user', 'content': prompt}],\n",
    "            options={'temperature': 0.1, 'num_predict': 128}\n",
    "        )\n",
    "        llm_output = response['message']['content'].strip()\n",
    "        # print(f\"LLM Raw Output:\\n{llm_output}\\n\")\n",
    "        lines = [line.strip() for line in llm_output.split('\\n') if line.strip()]\n",
    "        if lines:\n",
    "            return lines[0]\n",
    "        else:\n",
    "            return \"Error: LLM returned empty response.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error communicating with Ollama: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "28a097d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_llm_to_review_boolean_logic(natural_language_requirement: str, bool_vars:list, llm_boolean_logic_output) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert in formal logic and system specifications.\n",
    "    Your task is to review the Boolean logic expressions obtained from translate natural language design requirements.\n",
    "\n",
    "    Rules for Boolean Logic:\n",
    "    - Use 'AND' for logical conjunction.\n",
    "    - Use 'OR' for logical disjunction.\n",
    "    - Use 'NOT' for logical negation.\n",
    "    - Use 'IMPLIES' for logical implication (A IMPLIES B).\n",
    "    - Use parentheses for grouping everywhere so that its neatly understandable.\n",
    "    - Identify the clauses properly with more precision in the sentence and convert them into boolean specifications properly.\n",
    "    - Identify the main subject (e.g., 'software installation', 'system activation', 'alarm sounding') and include it as a variable in the final Boolean logic expression.\n",
    "    - Do not include any explanations, preamble, or additional text. Only output the Boolean logic expression.\n",
    "    - When you see 'only if' (not 'if') in the requirement like A only if B it is 'A implies B' not 'B implies A'\n",
    "    - When you see 'if and only if' (not 'only if') in the requirement like A if and only if B it is 'A implies B AND B implies A'\n",
    "\n",
    "    Used these boolean variables : \"{bool_vars}\"\n",
    "\n",
    "    For this Natural Language Requirement: \"{natural_language_requirement}\", the boolean logic output LLM gave was \n",
    "    Boolean Logic: \"{llm_boolean_logic_output}\"\n",
    "\n",
    "    Give me the issues point wise.\n",
    "\n",
    "    Issues: \n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model='llama3',\n",
    "            messages=[{'role': 'user', 'content': prompt}],\n",
    "            options={'temperature': 0.1, 'num_predict': 128}\n",
    "        )\n",
    "        llm_output = response['message']['content'].strip()\n",
    "        # print(f\"LLM Raw Output:\\n{llm_output}\\n\")\n",
    "        lines = [line.strip() for line in llm_output.split('\\n') if line.strip()]\n",
    "        if lines:\n",
    "            return lines[0]\n",
    "        else:\n",
    "            return \"Error: LLM returned empty response.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error communicating with Ollama: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c690f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Requirement 1 ---\n",
      "Natural Language: \"The system will install updates, except if there is not enough disk space or the update is not available.\"\n",
      "Ground Truth Boolean Logic: SOFTWARE_INSTALL IF ENOUGH_DISK_SPACE AND UPDATE_AVAILABLE\n",
      "\n",
      "DEBUG: Asking LLM to deconstruct the requirement.\n",
      "the system will install updates\n",
      "there is not enough disk space\n",
      "the update is not available\n",
      "1 : SYSTEM_UPDATES_INSTALLED\n",
      "1 : DISK_SPACE_AVAILABLE\n",
      "1 : UPDATE_AVAILABLE\n",
      "No issues detected.\n",
      "Final Boolean Logic: (NOT SYSTEM_UPDATES_INSTALLED) IMPLIES ((NOT DISK_SPACE_AVAILABLE) OR (NOT UPDATE_AVAILABLE))\n",
      "New Boolean Logic: SYSTEM_UPDATES_INSTALLED IMPLIES ((DISK_SPACE_AVAILABLE AND UPDATE_AVAILABLE) OR NOT SYSTEM_UPDATES_INSTALLED)\n",
      "New Boolean Logic: NOT (SYSTEM_UPDATES_INSTALLED IMPLIES NOT (DISK_SPACE_AVAILABLE OR UPDATE_AVAILABLE))\n",
      "New Boolean Logic: NOT (UPDATE_AVAILABLE IMPLIES (SYSTEM_UPDATES_INSTALLED AND DISK_SPACE_AVAILABLE))\n",
      "New Boolean Logic: NOT (UPDATE_AVAILABLE OR NOT DISK_SPACE_AVAILABLE) IMPLIES SYSTEM_UPDATES_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    llm_outputs = []\n",
    "    ground_truths = []\n",
    "\n",
    "    df = pd.read_csv('testreq.csv', dtype={'llm_output': str})\n",
    "\n",
    "    # Fill any NaN values with empty strings\n",
    "    df['llm_output'] = df['llm_output'].fillna('')\n",
    "\n",
    "    results = []\n",
    "    attempts = 0\n",
    "    nreq=0\n",
    "\n",
    "    for i, req_data in df.iterrows():\n",
    "        req = req_data[\"natural_language\"]\n",
    "        ground_truth_req = req_data[\"ground_truth\"]\n",
    "        \n",
    "        print(f\"\\n--- Requirement {i+1} ---\")\n",
    "        print(f\"Natural Language: \\\"{req}\\\"\")\n",
    "        print(f\"Ground Truth Boolean Logic: {ground_truth_req}\\n\")\n",
    "        \n",
    "        simple_sentences = deconstruct_requirement(req)\n",
    "        for i in simple_sentences:\n",
    "            print(i)\n",
    "        bool_vars = ask_llm_for_boolean_variables(simple_sentences)\n",
    "        vars = []\n",
    "        cnt=1\n",
    "        for sentence in enumerate(simple_sentences, start=1):\n",
    "            print(cnt,\":\", bool_vars[sentence])\n",
    "            vars.append(bool_vars[sentence])\n",
    "        \n",
    "        llm_boolean_logic_output = ask_llm_for_boolean_logic(req,vars)\n",
    "        # print(f\"LLM-generated Boolean Logic: {llm_boolean_logic_output}\")\n",
    "        # conistency = check_semantic_consistency(req, llm_boolean_logic_output, vars)\n",
    "        # print(conistency)\n",
    "        # continue\n",
    "        # result,attempt = manual_prompt_testing(natural_language_requirement=req, llm_boolean_logic_output=llm_boolean_logic_output)\n",
    "        # results.extend(result)\n",
    "        # attempts += attempt\n",
    "        # nreq+=1\n",
    "        # Update the specific row with the LLM output\n",
    "        df.at[i, 'llm_output'] = llm_boolean_logic_output\n",
    "        \n",
    "        # Write the updated DataFrame back to CSV after each iteration\n",
    "        # df.to_csv('testreq.csv', index=False)\n",
    "        # continue\n",
    "        # evaluate_compositional_logic(req, simple_sentences, llm_boolean_logic_output)\n",
    "        \n",
    "        llm_outputs.append(llm_boolean_logic_output)\n",
    "        ground_truths.append(ground_truth_req)\n",
    "\n",
    "        parsed_tree = parse_boolean_logic(llm_boolean_logic_output)\n",
    "\n",
    "        issues = run_comparator_general(parsed_tree, req, bool_vars)\n",
    "        new_llm_boolean_logic_output = llm_boolean_logic_output\n",
    "        new_parsed_tree = parsed_tree\n",
    "        while issues!=[]:\n",
    "            new_llm_boolean_logic_output = ask_llm_for_boolean_logic_revised(req, vars, issues, new_llm_boolean_logic_output)\n",
    "            new_parsed_tree = parse_boolean_logic(new_llm_boolean_logic_output)   \n",
    "            issues = run_comparator_general(new_parsed_tree, req, bool_vars)\n",
    "            print(f\"New Boolean Logic: {new_llm_boolean_logic_output}\")\n",
    "        print(f\"Final Boolean Logic: {new_llm_boolean_logic_output}\")\n",
    "        conistency = check_semantic_consistency(req, new_llm_boolean_logic_output, vars)\n",
    "        issues = ask_llm_to_review_boolean_logic(req, vars, new_llm_boolean_logic_output)\n",
    "        while issues!=[]:\n",
    "            new_llm_boolean_logic_output = ask_llm_for_boolean_logic_revised(req, vars, issues, new_llm_boolean_logic_output)\n",
    "            new_parsed_tree = parse_boolean_logic(new_llm_boolean_logic_output) \n",
    "            issues = ask_llm_to_review_boolean_logic(req, vars, new_llm_boolean_logic_output)\n",
    "            print(f\"New Boolean Logic: {new_llm_boolean_logic_output}\")\n",
    "        print(f\"Final Boolean Logic: {new_llm_boolean_logic_output}\")\n",
    "        continue\n",
    "        \n",
    "        if parsed_tree:\n",
    "            print(\"--- Pyparsing ParseResults Object (Raw) ---\")\n",
    "            print(parsed_tree)\n",
    "            print(\"\\n--- Visualizing the Parse Tree (Simplified Method) ---\")\n",
    "            visualize_tree(parsed_tree.asList())\n",
    "            print(\"\\n--- Pretty Printing the Parse Tree (More Structured Method) ---\")\n",
    "            pretty_print_tree(parsed_tree.asList())\n",
    "            # print(parsed_tree.asList())\n",
    "            print(\"\\n--- Transforming 'IMPLIES' to 'OR NOT' (Conceptual) ---\")\n",
    "            def transform_implies(node):\n",
    "                op, operands = _get_operator_and_operands(node)\n",
    "                # print(op, operands)\n",
    "                if op == 'IMPLIES':\n",
    "                    # print(f\"Transforming 'IMPLIES' node: {node}\")\n",
    "                    antecedent = transform_implies(operands[0])\n",
    "                    consequent = transform_implies(operands[1])\n",
    "                    return [['NOT', antecedent], 'OR' , consequent]\n",
    "                elif op:\n",
    "                    transformed_operands = [transform_implies(o) for o in operands]\n",
    "                    # print(transformed_operands, \"sdgk\")\n",
    "                    if op == 'NOT':\n",
    "                        return ['NOT', transformed_operands[0]]\n",
    "                    elif op in ['AND', 'OR']:\n",
    "                        return [[transformed_operands[0]], op, [transformed_operands[1]]]\n",
    "                elif operands is not None:\n",
    "                    return operands\n",
    "                else:\n",
    "                    print(f\"WARNING: transform_implies encountered unhandled node: {node}\")\n",
    "                    return node\n",
    "            transformed_tree = transform_implies(parsed_tree.asList())\n",
    "            # print(\"MEOW\")\n",
    "            # print(parsed_tree.asList())\n",
    "            # print(\"meowwww\")\n",
    "            # print(transformed_tree) \n",
    "            print(\"Transformed tree for 'IMPLIES' (Conceptual):\")\n",
    "            pretty_print_tree(transformed_tree)\n",
    "            print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "            # continue\n",
    "            # print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "            \n",
    "            print(\"\\n--- Processing LLM Output ---\")\n",
    "            \n",
    "            llm_variables = set()\n",
    "            extract_variables(parsed_tree.asList(), llm_variables)\n",
    "            print(f\"Extracted Variables from LLM: {llm_variables}\")\n",
    "            \n",
    "            semantic_map = {}\n",
    "            for var in llm_variables:\n",
    "                equivalents = get_semantic_equivalents(var)\n",
    "                print(f\" -> Found equivalents for '{var}': {equivalents}\")\n",
    "                semantic_map[var] = [var] + equivalents\n",
    "            \n",
    "            print(\"\\n--- Final Semantic Mapping Dictionary ---\")\n",
    "            print(semantic_map)\n",
    "            \n",
    "            parsed_human_tree = parse_boolean_logic(ground_truth_req)\n",
    "            human_variables = set()\n",
    "            if parsed_human_tree:\n",
    "                 extract_variables(parsed_human_tree.asList(), human_variables)\n",
    "                 print(f\"\\nExtracted Variables from Human Gold Standard: {human_variables}\")\n",
    "        \n",
    "            original_req_text = req_data[\"natural_language\"]\n",
    "            full_logic = llm_boolean_logic_output\n",
    "            \n",
    "            sentences_incorporated, total_sentences = measure_completeness(original_req_text, full_logic)\n",
    "            print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "        else:\n",
    "            print(\"Skipping processing due to parsing error.\")\n",
    "            print(\"\\n\" + \"=\"*70 + \"\\n\") \n",
    "    print(f\"\\nAll requirements processed. Total requirements: {nreq}, Total attempts: {attempts}\")\n",
    "    print(f\"Average attempts per requirement: {attempts/nreq if nreq>0 else 0}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
